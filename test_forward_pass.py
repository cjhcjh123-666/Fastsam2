#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å¤šä»»åŠ¡æ¨¡å‹çš„å‰å‘ä¼ æ’­å’Œlossè®¡ç®—
éªŒè¯å„ä¸ªä»»åŠ¡ç±»å‹çš„loss maskingæœºåˆ¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
import numpy as np
from mmengine.config import Config
from mmengine.registry import MODELS
from mmdet.structures import DetDataSample
from mmengine.structures import InstanceData, PixelData


def create_dummy_batch(task_type='interactive_image', batch_size=2, num_frames=1):
    """åˆ›å»ºè™šæ‹Ÿbatchæ•°æ®ç”¨äºæµ‹è¯•
    
    Args:
        task_type: ä»»åŠ¡ç±»å‹ ('interactive_image', 'interactive_video', 'vos', 'panoptic')
        batch_size: batchå¤§å°
        num_frames: è§†é¢‘å¸§æ•°ï¼ˆä»…è§†é¢‘ä»»åŠ¡ï¼‰
    
    Returns:
        batch_inputs, batch_data_samples
    """
    # åˆ›å»ºè¾“å…¥å›¾åƒ
    if task_type in ['interactive_video', 'vos']:
        # è§†é¢‘æ•°æ®: [B, T, C, H, W]
        batch_inputs = torch.randn(batch_size, num_frames, 3, 512, 512).cuda()
    else:
        # å›¾åƒæ•°æ®: [B, C, H, W]
        batch_inputs = torch.randn(batch_size, 3, 512, 512).cuda()
    
    batch_data_samples = []
    
    for i in range(batch_size):
        data_sample = DetDataSample()
        
        # è®¾ç½®metainfo
        data_sample.set_metainfo({
            'img_shape': (512, 512),
            'ori_shape': (512, 512),
            'pad_shape': (512, 512),
            'img_id': i,
        })
        
        # åˆ›å»ºGT instances
        gt_instances = InstanceData()
        num_instances = 5
        
        # æ·»åŠ masks - å¿…é¡»ä½¿ç”¨BitmapMaskså¯¹è±¡
        from mmdet.structures.mask import BitmapMasks
        masks_np = np.random.randint(0, 2, (num_instances, 512, 512), dtype=np.uint8)
        gt_instances.masks = BitmapMasks(masks_np, height=512, width=512)
        
        # æ·»åŠ labels
        gt_instances.labels = torch.randint(0, 80, (num_instances,)).cuda()
        
        # æ·»åŠ bboxes
        bboxes = torch.rand(num_instances, 4).cuda() * 512
        bboxes[:, 2:] = bboxes[:, 2:] + bboxes[:, :2]  # ç¡®ä¿x2>x1, y2>y1
        gt_instances.bboxes = bboxes
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ·»åŠ ç‰¹å®šæ•°æ®
        if task_type in ['interactive_image', 'interactive_video']:
            # äº¤äº’ä»»åŠ¡ï¼šæ·»åŠ prompt
            gt_instances_collected = InstanceData()
            # æ·»åŠ ç‚¹å‡»åæ ‡ - ä¿®æ­£ï¼šåº”è¯¥æ˜¯ (num_instances, 2) ç»´åº¦ï¼Œprepare_for_dn_mo ä¼š stack æˆ (B, N, 2)
            point_coords = torch.rand(num_instances, 2).cuda() * 512
            gt_instances_collected.point_coords = point_coords
            # æ·»åŠ ç‚¹å‡»æ ‡ç­¾ (1=å‰æ™¯, 0=èƒŒæ™¯) - (num_instances,)
            gt_instances_collected.pb_labels = torch.ones(num_instances, dtype=torch.long).cuda()
            data_sample.gt_instances_collected = gt_instances_collected
            
            # ğŸ”¥ å…³é”®ï¼šç»™æ‰€æœ‰äº¤äº’æ ·æœ¬éƒ½æ·»åŠ æ–‡æœ¬æç¤ºï¼Œç¡®ä¿loss_text_visualèƒ½æ¿€æ´»
            # ä¸åŒæ ·æœ¬ä½¿ç”¨ä¸åŒçš„textï¼Œæ¨¡æ‹ŸçœŸå®åœºæ™¯
            text_prompts = [
                'a person wearing red shirt',
                'a dog running in the park',
                'a car on the street',
            ]
            data_sample.set_metainfo({'text': text_prompts[i % len(text_prompts)]})
        
        elif task_type == 'vos':
            # VOSä»»åŠ¡ï¼šæ·»åŠ å®ä¾‹IDç”¨äºè·Ÿè¸ª
            gt_instances.instances_ids = torch.arange(num_instances).cuda()
        
        # å¯¹äºpanopticä»»åŠ¡ï¼Œä¸éœ€è¦é¢å¤–æ•°æ®
        
        data_sample.gt_instances = gt_instances
        batch_data_samples.append(data_sample)
    
    # å¦‚æœæ˜¯è§†é¢‘ä»»åŠ¡ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
    if task_type in ['interactive_video', 'vos']:
        from mmdet.structures import TrackDataSample
        from mmdet.structures.mask import BitmapMasks
        track_samples = []
        
        for i in range(batch_size):
            track_sample = TrackDataSample()
            # åˆ›å»ºå¤šå¸§æ•°æ®
            video_data_samples = []
            
            # å¯¹äºVOSä»»åŠ¡ï¼Œæ‰€æœ‰å¸§çš„labelså¿…é¡»ä¸€è‡´
            # æå‰ç”Ÿæˆå›ºå®šçš„labels
            fixed_labels = torch.randint(0, 80, (num_instances,)).cuda()
            
            for t in range(num_frames):
                # ä¸ºæ¯ä¸€å¸§åˆ›å»ºç‹¬ç«‹çš„æ•°æ®æ ·æœ¬
                frame_sample = DetDataSample()
                frame_sample.set_metainfo({
                    'img_shape': (512, 512),
                    'ori_shape': (512, 512),
                    'pad_shape': (512, 512),
                    'img_id': i * num_frames + t,
                    'frame_id': t,
                })
                
                # åˆ›å»ºè¯¥å¸§çš„GT instances
                frame_instances = InstanceData()
                masks_np = np.random.randint(0, 2, (num_instances, 512, 512), dtype=np.uint8)
                frame_instances.masks = BitmapMasks(masks_np, height=512, width=512)
                
                # ä½¿ç”¨å›ºå®šçš„labelsï¼ˆVOSè¦æ±‚æ‰€æœ‰å¸§labelsä¸€è‡´ï¼‰
                frame_instances.labels = fixed_labels.clone()
                
                bboxes = torch.rand(num_instances, 4).cuda() * 512
                bboxes[:, 2:] = bboxes[:, 2:] + bboxes[:, :2]
                frame_instances.bboxes = bboxes
                
                # åªæœ‰VOSä»»åŠ¡éœ€è¦å®ä¾‹ID
                if task_type == 'vos':
                    frame_instances.instances_ids = torch.arange(num_instances).cuda()
                
                # äº¤äº’è§†é¢‘ä»»åŠ¡ï¼šæ·»åŠ promptï¼ˆä»…ç¬¬ä¸€å¸§ï¼‰
                if task_type == 'interactive_video' and t == 0:
                    gt_instances_collected = InstanceData()
                    # ä¿®æ­£ç»´åº¦ï¼š(num_instances, 2)
                    point_coords = torch.rand(num_instances, 2).cuda() * 512
                    gt_instances_collected.point_coords = point_coords
                    # ä¿®æ­£ç»´åº¦ï¼š(num_instances,)
                    gt_instances_collected.pb_labels = torch.ones(num_instances, dtype=torch.long).cuda()
                    frame_sample.gt_instances_collected = gt_instances_collected
                    
                    # ğŸ”¥ ç»™æ‰€æœ‰è§†é¢‘äº¤äº’æ ·æœ¬éƒ½æ·»åŠ æ–‡æœ¬æç¤º
                    text_prompts = [
                        'a person wearing red shirt',
                        'a dog running in the park',
                    ]
                    frame_sample.set_metainfo({'text': text_prompts[i % len(text_prompts)]})
                
                frame_sample.gt_instances = frame_instances
                video_data_samples.append(frame_sample)
            
            track_sample.video_data_samples = video_data_samples
            track_samples.append(track_sample)
        
        batch_data_samples = track_samples
    
    return batch_inputs, batch_data_samples


def test_forward_pass(config_path='/mnt/chenjiahui/Fastsam2-main/configs/rap_sam/rap_sam_r50_12e_adaptor.py'):
    """æµ‹è¯•å‰å‘ä¼ æ’­å’Œlossè®¡ç®—"""
    
    print("=" * 80)
    print("æµ‹è¯•å¤šä»»åŠ¡æ¨¡å‹å‰å‘ä¼ æ’­")
    print("=" * 80)
    
    # åŠ è½½é…ç½®
    print("\n[1] åŠ è½½é…ç½®æ–‡ä»¶...")
    try:
        cfg = Config.fromfile(config_path)
        print("âœ“ é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âœ— é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False
    
    # æ„å»ºæ¨¡å‹
    print("\n[2] æ„å»ºæ¨¡å‹...")
    try:
        model = MODELS.build(cfg.model)
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†SyncBatchNormè½¬æ¢ä¸ºBatchNormç”¨äºå•GPUæµ‹è¯•
        # è¿™æ ·å¯ä»¥é¿å…åˆ†å¸ƒå¼åˆå§‹åŒ–çš„è¦æ±‚
        from torch.nn import SyncBatchNorm
        print("   è½¬æ¢ SyncBatchNorm -> BatchNorm (å•GPUæ¨¡å¼)...")
        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)
        # å®é™…ä¸Šæˆ‘ä»¬éœ€è¦åå‘è½¬æ¢ï¼Œå°†SyncBNè½¬ä¸ºæ™®é€šBN
        def convert_sync_bn_to_bn(module):
            """é€’å½’è½¬æ¢SyncBatchNormä¸ºBatchNorm"""
            import torch.nn as nn
            module_output = module
            if isinstance(module, SyncBatchNorm):
                module_output = nn.BatchNorm2d(
                    module.num_features,
                    module.eps,
                    module.momentum,
                    module.affine,
                    module.track_running_stats
                )
                if module.affine:
                    with torch.no_grad():
                        module_output.weight = module.weight
                        module_output.bias = module.bias
                module_output.running_mean = module.running_mean
                module_output.running_var = module.running_var
                module_output.num_batches_tracked = module.num_batches_tracked
            for name, child in module.named_children():
                module_output.add_module(name, convert_sync_bn_to_bn(child))
            del module
            return module_output
        
        model = convert_sync_bn_to_bn(model)
        
        model = model.cuda()
        model.train()
        print("âœ“ æ¨¡å‹æ„å»ºæˆåŠŸ")
        print(f"   - ä½¿ç”¨TaskRouter: {model.use_task_router}")
        print(f"   - ä½¿ç”¨StreamingMemory: {model.use_streaming_memory}")
        print(f"   - ä½¿ç”¨PromptFusion: {model.use_prompt_fusion}")
        print(f"   - Lossæƒé‡é…ç½®: {len(model.task_loss_weights)} ä¸ªä»»åŠ¡ç±»å‹")
    except Exception as e:
        print(f"âœ— æ¨¡å‹æ„å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æµ‹è¯•ä¸åŒä»»åŠ¡ç±»å‹
    task_types = [
        ('interactive_image', 'å›¾åƒäº¤äº’åˆ†å‰²', 1),
        ('interactive_video', 'è§†é¢‘äº¤äº’åˆ†å‰²', 3),
        ('vos', 'è§†é¢‘å¯¹è±¡åˆ†å‰²', 3),
        ('panoptic', 'å…¨æ™¯åˆ†å‰²', 1),
    ]
    
    all_passed = True
    
    for task_type, task_name, num_frames in task_types:
        print(f"\n[3] æµ‹è¯•ä»»åŠ¡ç±»å‹: {task_name} ({task_type})")
        print("-" * 60)
        
        try:
            # åˆ›å»ºè™šæ‹Ÿæ•°æ®
            batch_inputs, batch_data_samples = create_dummy_batch(
                task_type=task_type, 
                batch_size=2, 
                num_frames=num_frames
            )
            print(f"   âœ“ åˆ›å»ºæµ‹è¯•æ•°æ®: batch_size=2, num_frames={num_frames}")
            print(f"     è¾“å…¥å½¢çŠ¶: {batch_inputs.shape}")
            
            # å‰å‘ä¼ æ’­ - lossè®¡ç®—
            with torch.cuda.amp.autocast(enabled=False):  # ä¸ä½¿ç”¨æ··åˆç²¾åº¦ä»¥ä¾¿è°ƒè¯•
                losses = model.loss(batch_inputs, batch_data_samples)
            
            print(f"   âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"\n   è®¡ç®—çš„Loss:")
            
            total_loss_value = 0.0
            active_losses = []
            masked_losses = []
            
            for loss_name, loss_value in losses.items():
                loss_val = loss_value.item() if isinstance(loss_value, torch.Tensor) else loss_value
                total_loss_value += loss_val
                
                # åˆ¤æ–­lossæ˜¯å¦è¢«æ¿€æ´»ï¼ˆæƒé‡>0ï¼‰
                if loss_val > 1e-6:  # éé›¶loss
                    status = "âœ“ æ¿€æ´»"
                    active_losses.append(loss_name)
                else:
                    status = "â—‹ å±è”½"
                    masked_losses.append(loss_name)
                
                print(f"     {status} {loss_name:25s}: {loss_val:>12.6f}")
            
            print(f"\n   æ€»Losså€¼: {total_loss_value:.6f}")
            print(f"   æ¿€æ´»çš„Loss ({len(active_losses)}ä¸ª): {', '.join(active_losses)}")
            print(f"   å±è”½çš„Loss ({len(masked_losses)}ä¸ª): {', '.join(masked_losses)}")
            
            # éªŒè¯loss maskingæ˜¯å¦æ­£ç¡®
            # æå–åŸºç¡€lossåç§°ï¼ˆå»æ‰decoderå±‚å‰ç¼€ï¼‰
            def get_base_loss_name(loss_name):
                return loss_name.split('.')[-1] if '.' in loss_name else loss_name
            
            # å®šä¹‰æ¯ä¸ªä»»åŠ¡åº”è¯¥æ¿€æ´»çš„lossï¼ˆåŸºç¡€loss + ä»»åŠ¡ç‰¹å®šlossï¼‰
            expected_active_base = {
                'interactive_image': ['loss_mask', 'loss_dice', 'loss_iou', 'loss_prompt_align', 'loss_text_visual'],
                'interactive_video': ['loss_mask', 'loss_dice', 'loss_iou', 'loss_prompt_align', 'loss_text_visual', 'loss_temporal'],
                'vos': ['loss_cls', 'loss_mask', 'loss_dice', 'loss_dpsr', 'loss_temporal', 'loss_memory_align'],
                'panoptic': ['loss_cls', 'loss_mask', 'loss_dice', 'loss_panoptic'],
            }
            
            # å®šä¹‰æ¯ä¸ªä»»åŠ¡åº”è¯¥å±è”½çš„loss
            expected_masked_base = {
                'interactive_image': ['loss_cls', 'loss_dpsr', 'loss_temporal', 'loss_memory_align', 'loss_panoptic'],
                'interactive_video': ['loss_cls', 'loss_dpsr', 'loss_memory_align', 'loss_panoptic'],
                'vos': ['loss_iou', 'loss_prompt_align', 'loss_text_visual', 'loss_panoptic'],
                'panoptic': ['loss_iou', 'loss_dpsr', 'loss_temporal', 'loss_prompt_align', 'loss_text_visual', 'loss_memory_align'],
            }
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åº”è¯¥æ¿€æ´»ä½†æœªæ¿€æ´»çš„loss
            expected_active = expected_active_base.get(task_type, [])
            expected_masked = expected_masked_base.get(task_type, [])
            active_base_losses = [get_base_loss_name(l) for l in active_losses]
            masked_base_losses = [get_base_loss_name(l) for l in masked_losses]
            
            # å»é‡ï¼ˆå› ä¸ºd0/d1/d2ä¼šé‡å¤ï¼‰
            active_base_losses_unique = list(set(active_base_losses))
            masked_base_losses_unique = list(set(masked_base_losses))
            
            # æ£€æŸ¥ç¼ºå¤±çš„æ¿€æ´»loss
            missing_active = [l for l in expected_active if l not in active_base_losses_unique]
            # æ£€æŸ¥ä¸åº”è¯¥æ¿€æ´»çš„loss
            unexpected_active = [l for l in expected_masked if l in active_base_losses_unique]
            # æ£€æŸ¥åº”è¯¥å±è”½ä½†æœªå±è”½çš„loss
            missing_masked = [l for l in expected_masked if l not in masked_base_losses_unique and l not in active_base_losses_unique]
            # æ£€æŸ¥ä¸åº”è¯¥å±è”½çš„loss
            unexpected_masked = [l for l in expected_active if l in masked_base_losses_unique]
            
            # æ‰“å°è¯¦ç»†çš„éªŒè¯ç»“æœ
            validation_passed = True
            if missing_active:
                print(f"\n   âŒ é”™è¯¯: ä»¥ä¸‹lossåº”è¯¥æ¿€æ´»ä½†æœªæ¿€æ´»: {missing_active}")
                validation_passed = False
            if unexpected_active:
                print(f"   âŒ é”™è¯¯: ä»¥ä¸‹lossä¸åº”è¯¥æ¿€æ´»ä½†è¢«æ¿€æ´»: {unexpected_active}")
                validation_passed = False
            if unexpected_masked:
                print(f"   âŒ é”™è¯¯: ä»¥ä¸‹lossä¸åº”è¯¥å±è”½ä½†è¢«å±è”½: {unexpected_masked}")
                validation_passed = False
            
            if validation_passed:
                print(f"\n   âœ… LosséªŒè¯é€šè¿‡: æ‰€æœ‰lossçš„æ¿€æ´»/å±è”½çŠ¶æ€æ­£ç¡®")
            else:
                all_passed = False
            
            # æµ‹è¯•åå‘ä¼ æ’­
            total_loss = sum(losses.values())
            total_loss.backward()
            print(f"\n   âœ“ åå‘ä¼ æ’­æˆåŠŸ")
            
            # æ£€æŸ¥æ¢¯åº¦
            has_grad = False
            no_grad_params = []
            for name, param in model.named_parameters():
                if param.requires_grad:
                    if param.grad is not None and param.grad.abs().sum() > 0:
                        has_grad = True
                    elif param.grad is None:
                        no_grad_params.append(name)
            
            if has_grad:
                print(f"   âœ“ æ¢¯åº¦è®¡ç®—æ­£å¸¸")
            else:
                print(f"   âœ— è­¦å‘Š: æ²¡æœ‰å‚æ•°æœ‰æ¢¯åº¦")
                all_passed = False
            
            if no_grad_params and len(no_grad_params) < 10:  # åªæ˜¾ç¤ºå‰å‡ ä¸ª
                print(f"   âš  éƒ¨åˆ†å‚æ•°æ— æ¢¯åº¦: {no_grad_params[:5]}...")
            
            # æ¸…ç†æ¢¯åº¦
            model.zero_grad()
            
            print(f"\n   âœ… {task_name} æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            print(f"\n   âœ— {task_name} æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            all_passed = False
    
    print("\n" + "=" * 80)
    if all_passed:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤šä»»åŠ¡loss maskingæœºåˆ¶å·¥ä½œæ­£å¸¸ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯ã€‚")
    print("=" * 80)
    
    return all_passed


if __name__ == '__main__':
    import sys
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    # è¿è¡Œæµ‹è¯•
    success = test_forward_pass()
    
    sys.exit(0 if success else 1)

